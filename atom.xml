<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jthu的博客</title>
  
  <subtitle>后端技术</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hicker000.github.io/"/>
  <updated>2020-02-25T14:48:16.389Z</updated>
  <id>https://hicker000.github.io/</id>
  
  <author>
    <name>jthu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>保证消息的可靠性</title>
    <link href="https://hicker000.github.io/2020/02/25/%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/"/>
    <id>https://hicker000.github.io/2020/02/25/%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/</id>
    <published>2020-02-25T07:30:51.000Z</published>
    <updated>2020-02-25T14:48:16.389Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？</p></blockquote><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p><img src="/images/%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/image-20200225224640893.png" alt="image-20200225224640893"></p><h4 id="生产者弄丢了数据"><a href="#生产者弄丢了数据" class="headerlink" title="生产者弄丢了数据"></a>生产者弄丢了数据</h4><ul><li><p>生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。</p></li><li><p>此时可以选择用 RabbitMQ 提供的事务功能，就是生产者<strong>发送数据之前</strong>开启 RabbitMQ 事务<code>channel.txSelect</code>，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务<code>channel.txRollback</code>，然后重试发送消息；如果收到了消息，那么可以提交事务<code>channel.txCommit</code>。</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启事务</span></span><br><span class="line">channel.txSelect</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 这里发送消息</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    channel.txRollback</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里再次重发这条消息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交事务</span></span><br><span class="line">channel.txCommit</span><br></pre></td></tr></table></figure><blockquote><p> 但是问题是，RabbitMQ 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p></blockquote><ul><li><p>所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 <code>confirm</code> 模式，在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p></li><li><p>事务机制和 <code>confirm</code> 机制最大的不同在于，<strong>事务机制是同步的</strong>，你提交一个事务之后会<strong>阻塞</strong>在那儿，但是 <code>confirm</code> 机制是<strong>异步</strong>的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。</p></li><li><p>所以一般在生产者这块<strong>避免数据丢失</strong>，都是用 <code>confirm</code> 机制的。</p></li></ul><h4 id="RabbitMQ-弄丢了数据"><a href="#RabbitMQ-弄丢了数据" class="headerlink" title="RabbitMQ 弄丢了数据"></a>RabbitMQ 弄丢了数据</h4><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p><p>设置持久化有<strong>两个步骤</strong>：</p><ul><li><p>创建 queue 的时候将其设置为持久化<br><br>这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。</p></li><li><p>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2<br><br>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</p></li><li><p>必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p></li><li><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还<strong>没来得及持久化到磁盘上</strong>，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p></li><li><p>所以，持久化可以跟生产者那边的 <code>confirm</code> 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 <code>ack</code> 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 <code>ack</code>，你也是可以自己重发的。</p></li></ul><h4 id="消费端弄丢了数据"><a href="#消费端弄丢了数据" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><ul><li>如果丢失了数据，主要是因为你消费的时候，<strong>刚消费到，还没处理，结果进程挂了</strong>，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</li></ul><ul><li>这个时候得用 RabbitMQ 提供的 <code>ack</code> 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 <code>ack</code>，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 <code>ack</code> 一把。这样的话，如果你还没处理完，不就没有 <code>ack</code> 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。</li></ul><p><img src="/images/%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/image-20200225224727268.png" alt="image-20200225224727268"></p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h4 id="消费端弄丢了数据-1"><a href="#消费端弄丢了数据-1" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><ul><li>唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边<strong>自动提交了 offset</strong>，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</li><li>这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要<strong>关闭自动提交</strong> offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是<strong>可能会有重复消费</strong>，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</li><li>生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。</li></ul><h4 id="Kafka-弄丢了数据"><a href="#Kafka-弄丢了数据" class="headerlink" title="Kafka 弄丢了数据"></a>Kafka 弄丢了数据</h4><ul><li>这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。</li></ul><ul><li>生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。</li></ul><p>所以此时一般是要求起码设置如下 4 个参数：</p><ul><li><p>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</p></li><li><p>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</p></li><li><p>在 producer 端设置 <code>acks=all</code>：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</p></li><li><p>在 producer 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</p></li><li><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p></li></ul><h4 id="生产者会不会弄丢数据？"><a href="#生产者会不会弄丢数据？" class="headerlink" title="生产者会不会弄丢数据？"></a>生产者会不会弄丢数据？</h4><p>如果按照上述的思路设置了 <code>acks=all</code>，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;RabbitMQ&quot;&gt;&lt;a href=&quot;#RabbitMQ&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="消息中间件" scheme="https://hicker000.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="面试题" scheme="https://hicker000.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>常见面试题</title>
    <link href="https://hicker000.github.io/2020/02/25/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>https://hicker000.github.io/2020/02/25/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</id>
    <published>2020-02-25T07:07:14.000Z</published>
    <updated>2020-02-25T13:11:44.883Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="为什么使用消息队列？"><a href="#为什么使用消息队列？" class="headerlink" title="为什么使用消息队列？ "></a>为什么使用消息队列？ </h2><p>其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？</p><p>面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用MQ可能会很麻烦，但是你现在用了MQ之后带给了你很多的好处。消息队列的常见使用场景，其实场景有很多，但是比较核心的有3个：解耦、异步、削峰。</p><h3 id="解耦："><a href="#解耦：" class="headerlink" title="解耦："></a>解耦：</h3><p>A系统发送个数据到BCD三个系统，接口调用发送，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？而且A系统要时时刻刻考虑BCDE四个系统如果挂了咋办？要不要重发？我要不要把消息存起来？</p><p>你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用MQ给他异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个MQ去进行系统的解耦。</p><h3 id="异步："><a href="#异步：" class="headerlink" title="异步："></a>异步：</h3><p>A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要30ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是30</p><ul><li>300 + 450 + 200 =<br>980ms，接近1s，异步后，BCD三个系统分别写库的时间，A系统就不再考虑了。</li></ul><h3 id="削峰："><a href="#削峰：" class="headerlink" title="削峰："></a>削峰：</h3><p>每天0点到16点，A系统风平浪静，每秒并发请求数量就100个。结果每次一到16点~23点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊。怎么办？需要我们进行流量的削峰，让系统可以平缓的处理突增的请求。</p><p><img src="/images/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/image-20200225155001340.png" alt="image-20200225155001340"></p><h2 id="消息队列有什么优点和缺点"><a href="#消息队列有什么优点和缺点" class="headerlink" title="消息队列有什么优点和缺点?"></a>消息队列有什么优点和缺点?</h2><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。</p><p>缺点呢？</p><h3 id="系统可用性降低"><a href="#系统可用性降低" class="headerlink" title="系统可用性降低"></a>系统可用性降低</h3><p>系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，ABCD四个系统好好的，没啥问题，你偏加个MQ进来，万一MQ挂了怎么办？MQ挂了，整套系统崩溃了，业务也就停顿了。</p><h3 id="系统复杂性提高"><a href="#系统复杂性提高" class="headerlink" title="系统复杂性提高"></a>系统复杂性提高</h3><p>硬生生加个MQ进来，怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？</p><h3 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h3><p>A系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，你这数据就不一致了。</p><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉。</p><h2 id="常见消息队列的比较"><a href="#常见消息队列的比较" class="headerlink" title="常见消息队列的比较 "></a>常见消息队列的比较 </h2><p>参见第一章中消息队列的比较章节。</p><h2 id="消息的重复"><a href="#消息的重复" class="headerlink" title="消息的重复 "></a>消息的重复 </h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><h4 id="第一类原因"><a href="#第一类原因" class="headerlink" title="第一类原因"></a>第一类原因</h4><p>消息发送端应用的消息重复发送,有以下几种情况。</p><ul><li><p>消息发送端发送消息给消息中间件,消息中间件收到消息并成功存储,而这时消息中间件出现了问题,导致应用端没有收到消息发送成功的返回因而进行重试产生了重复。</p></li><li><p>消息中间件因为负载高响应变慢,成功把消息存储到消息存储中后,返回“成功”这个结果时超时。</p></li><li><p>消息中间件将消息成功写入消息存储,在返回结果时网络出现问题,导致应用发送端重试,而重试时网络恢复,由此导致重复。</p></li></ul><p>可以看到,通过消息发送端产生消息重复的主要原因是消息成功进入消息存储后,因为各种原因使得消息发送端没有收到“成功”的返回结果,并且又有重试机制,因而导致重复。</p><h4 id="第二类原因"><a href="#第二类原因" class="headerlink" title="第二类原因"></a>第二类原因</h4><p>消息到达了消息存储,由消息中间件进行向外的投递时产生重复，有以下几种情况。</p><ul><li><p>消息被投递到消息接收者应用进行处理,处理完毕后应用出问题了,消息中间件不知道消息处理结果,会再次投递。</p></li><li><p>消息被投递到消息接收者应用进行处理,处理完毕后网络出现问题了,消息中间件没有收到消息处理结果,会再次投递。</p></li><li><p>消息被投递到消息接收者应用进行处理,处理时间比较长,消息中间件因为消息超时会再次投递。</p></li><li><p>消息被投递到消息接收者应用进行处理,处理完毕后消息中间件出问题了,没能收到消息结果并处理,会再次投递</p></li><li><p>消息被投递到消息接收者应用进行处理,处理完毕后消息中间件收到结果但是遇到消息存储故障,没能更新投递状态,会再次投递。</p></li></ul><p>可以看到,在投递过程中产生的消息重复接收主要是因为消息接收者成功处理完消息后,消息中间件不能及时更新投递状态造成的。</p><h3 id="如何解决重复消费"><a href="#如何解决重复消费" class="headerlink" title="如何解决重复消费"></a>如何解决重复消费</h3><p>那么有什么办法可以解决呢?主要是要求消息接收者来处理这种重复的情况,也就是要求消息接收者的消息处理是幂等操作。</p><h4 id="什么是幂等性？"><a href="#什么是幂等性？" class="headerlink" title="什么是幂等性？"></a>什么是幂等性？</h4><p>对于消息接收端的情况,幂等的含义是采用同样的输入多次调用处理函数,得到同样的结果。例如，一个SQL操作</p><p>update stat_table set count= 10 where id =1</p><p>这个操作多次执行,id等于1的记录中的<br>count字段的值都为10,这个操作就是幂等的,我们不用担心这个操作被重复。</p><p>再来看另外一个SQL操作</p><p>update stat_table set count= count +1 where id= 1;</p><p>这样的SQL操作就不是幂等的,一旦重复,结果就会产生变化。</p><h4 id="常见办法"><a href="#常见办法" class="headerlink" title="常见办法"></a>常见办法</h4><p>因此应对消息重复的办法是,使消息接收端的处理是一个幂等操作。这样的做法降低了消息中间件的整体复杂性,不过也给使用消息中间件的消息接收端应用带来了一定的限制和门槛。</p><h5 id="1-MVCC："><a href="#1-MVCC：" class="headerlink" title="1. MVCC："></a>1. MVCC：</h5><p>多版本并发控制，乐观锁的一种实现，在生产者发送消息时进行数据更新时需要带上数据的版本号，消费者去更新时需要去比较持有数据的版本号，版本号不一致的操作无法成功。例如博客点赞次数自动+1的接口：</p><p>public boolean addCount(Long id, Long version);</p><p>update blogTable set count= count+1,version=version+1 where id=321 and<br>version=123</p><p>每一个version只有一次执行成功的机会，一旦失败了生产者必须重新获取数据的最新版本号再次发起更新。</p><h5 id="2-去重表："><a href="#2-去重表：" class="headerlink" title="2. 去重表："></a>2. 去重表：</h5><p>利用数据库表单的特性来实现幂等，常用的一个思路是在表上构建唯一性索引，保证某一类数据一旦执行完毕，后续同样的请求不再重复处理了（利用一张日志表来记录已经处理成功的消息的ID，如果新到的消息ID已经在日志表中，那么就不再处理这条消息。）</p><p>以电商平台为例子，电商平台上的订单id就是最适合的token。当用户下单时，会经历多个环节，比如生成订单，减库存，减优惠券等等。每一个环节执行时都先检测一下该订单id是否已经执行过这一步骤，对未执行的请求，执行操作并缓存结果，而对已经执行过的id，则直接返回之前的执行结果，不做任何操作。这样可以在最大程度上避免操作的重复执行问题，缓存起来的执行结果也能用于事务的控制等。</p><h2 id="消息的可靠性传输"><a href="#消息的可靠性传输" class="headerlink" title="消息的可靠性传输 "></a>消息的可靠性传输 </h2><h3 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h3><p>要保证消息的可靠性，除了消息的持久化，还包括两个方面，一是生产者发送的消息可以被ActiveMQ收到，二是消费者收到了ActiveMQ发送的消息。</p><h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><p>非持久化又不在事务中的消息，可能会有消息的丢失。为保证消息可以被ActiveMQ收到，我们应该采用事务消息或持久化消息。</p><h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><p>对消息的确认有4种机制</p><ol><li><p>AUTO_ACKNOWLEDGE = 1    自动确认</p></li><li><p>CLIENT_ACKNOWLEDGE = 2    客户端手动确认   </p></li><li><p>DUPS_OK_ACKNOWLEDGE = 3    自动批量确认</p></li><li><p>SESSION_TRANSACTED = 0    事务提交并确认</p></li></ol><p>ACK_MODE描述了Consumer与broker确认消息的方式(时机),比如当消息被Consumer接收之后,Consumer将在何时确认消息。所以ack_mode描述的不是producer于broker之间的关系，而是customer于broker之间的关系。</p><p>对于broker而言，只有接收到ACK指令,才会认为消息被正确的接收或者处理成功了,通过ACK，可以在consumer与Broker之间建立一种简单的“担保”机制.</p><h5 id="AUTO-ACKNOWLEDGE"><a href="#AUTO-ACKNOWLEDGE" class="headerlink" title="AUTO_ACKNOWLEDGE"></a>AUTO_ACKNOWLEDGE</h5><p>自动确认</p><pre><code>“同步”(receive)方法返回message给消息时会立即确认。</code></pre><p>在”异步”(messageListener)方式中,将会首先调用listener.onMessage(message)，如果onMessage方法正常结束,消息将会正常确认。如果onMessage方法异常，将导致消费者要求ActiveMQ重发消息。</p><h5 id="CLIENT-ACKNOWLEDGE"><a href="#CLIENT-ACKNOWLEDGE" class="headerlink" title="CLIENT_ACKNOWLEDGE :"></a>CLIENT_ACKNOWLEDGE :</h5><p>客户端手动确认，这就意味着AcitveMQ将不会“自作主张”的为你ACK任何消息，开发者需要自己择机确认。</p><p>我们可以在当前消息处理成功之后，立即调用message.acknowledge()方法来”逐个”确认消息，这样可以尽可能的减少因网络故障而导致消息重发的个数；当然也可以处理多条消息之后，间歇性的调用acknowledge方法来一次确认多条消息，减少ack的次数来提升consumer的效率，不过需要自行权衡。</p><h5 id="DUPS-OK-ACKNOWLEDGE"><a href="#DUPS-OK-ACKNOWLEDGE" class="headerlink" title="DUPS_OK_ACKNOWLEDGE"></a>DUPS_OK_ACKNOWLEDGE</h5><p>类似于AUTO_ACK确认机制，为自动批量确认而生，而且具有“延迟”确认的特点，ActiveMQ会根据内部算法，在收到一定数量的消息自动进行确认。在此模式下，可能会出现重复消息，什么时候？当consumer故障重启后，那些尚未ACK的消息会重新发送过来。</p><h5 id="SESSION-TRANSACTED"><a href="#SESSION-TRANSACTED" class="headerlink" title="SESSION_TRANSACTED"></a>SESSION_TRANSACTED</h5><p>当session使用事务时，就是使用此模式。当决定事务中的消息可以确认时，必须调用session.commit()方法，commit方法将会导致当前session的事务中所有消息立即被确认。在事务开始之后的任何时机调用rollback()，意味着当前事务的结束，事务中所有的消息都将被重发。当然在commit之前抛出异常，也会导致事务的rollback。</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><h4 id="（1）生产者弄丢了数据"><a href="#（1）生产者弄丢了数据" class="headerlink" title="（1）生产者弄丢了数据"></a>（1）生产者弄丢了数据</h4><p>生产者将数据发送到RabbitMQ的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务（channel.txSelect），然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，RabbitMQ事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p><p>所以一般来说，如果要确保RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你说这个消息ok了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你一个接口通知你这个消息接收到了。</p><p>所以一般在生产者这块避免数据丢失，都是用confirm机制的。</p><h4 id="（2）RabbitMQ弄丢了数据"><a href="#（2）RabbitMQ弄丢了数据" class="headerlink" title="（2）RabbitMQ弄丢了数据"></a>（2）RabbitMQ弄丢了数据</h4><p>就是RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。</p><p>设置持久化有两个步骤，第一个是创建queue和交换器的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化相关的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。</p><p>而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。</p><p>哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果不巧，此时RabbitMQ挂了，就会导致内存里的一点点数据会丢失。</p><h4 id="（3）消费端弄丢了数据"><a href="#（3）消费端弄丢了数据" class="headerlink" title="（3）消费端弄丢了数据"></a>（3）消费端弄丢了数据</h4><p>RabbitMQ如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ认为你都消费了，这数据就丢了。</p><p>这个时候得用RabbitMQ提供的ack机制，简单来说，就是你关闭RabbitMQ自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。</p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h4 id="（1）消费端弄丢了数据"><a href="#（1）消费端弄丢了数据" class="headerlink" title="（1）消费端弄丢了数据"></a>（1）消费端弄丢了数据</h4><p>唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p><p>大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p><p>生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。</p><p>然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了</p><h4 id="（2）kafka弄丢了数据"><a href="#（2）kafka弄丢了数据" class="headerlink" title="（2）kafka弄丢了数据"></a>（2）kafka弄丢了数据</h4><p>这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。</p><p>所以此时一般是要求起码设置如下4个参数：</p><p>给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本。</p><p>在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧。</p><p>在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了。</p><p>在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。</p><h4 id="（3）生产者会不会弄丢数据"><a href="#（3）生产者会不会弄丢数据" class="headerlink" title="（3）生产者会不会弄丢数据"></a>（3）生产者会不会弄丢数据</h4><p>如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><h2 id="消息的顺序性"><a href="#消息的顺序性" class="headerlink" title="消息的顺序性"></a>消息的顺序性</h2><p>从根本上说，异步消息是不应该有顺序依赖的。在MQ上估计是没法解决。要实现严格的顺序消息，简单且可行的办法就是：保证生产者</p><ul><li>MQServer - 消费者是一对一对一的关系。</li></ul><h3 id="ActiveMQ-1"><a href="#ActiveMQ-1" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h3><p>1、通过高级特性consumer独有消费者（exclusive consumer）</p><p>queue = new ActiveMQQueue(“TEST.QUEUE?consumer.exclusive=true”);</p><p>consumer = session.createConsumer(queue);</p><p>当在接收信息的时候，有多个独占消费者的时候，只有一个独占消费者可以接收到消息。</p><p><img src="/images/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/image-20200225155018371.png" alt="image-20200225155018371"></p><p>独占消息就是在有多个消费者同时消费一个queue时，可以保证只有一个消费者可以消费消息，这样虽然保证了消息的顺序问题，不过也带来了一个问题，就是这个queue的所有消息将只会在这一个主消费者上消费，其他消费者将闲置，达不到负载均衡分配，而实际业务我们可能更多的是这样的场景，比如一个订单会发出一组顺序消息，我们只要求这一组消息是顺序消费的，而订单与订单之间又是可以并行消费的，不需要顺序，因为顺序也没有任何意义，有没有办法做到呢？可以利用activemq的另一个高级特性之messageGroup</p><p>2、利用Activemq的高级特性：messageGroups</p><p>Message<br>Groups特性是一种负载均衡的机制。在一个消息被分发到consumer之前，broker首先检查消息JMSXGroupID属性。如果存在，那么broker会检查是否有某个consumer拥有这个message<br>group。如果没有，那么broker会选择一个consumer，并将它关联到这个message<br>group。此后，这个consumer会接收这个message<br>group的所有消息，直到：Consumer被关闭。Message<br>group被关闭，通过发送一个消息，并设置这个消息的JMSXGroupSeq为-1</p><p><img src="/images/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/image-20200225155029440.png" alt="image-20200225155029440"></p><p><strong>bytesMessage</strong>.setStringProperty(“JMSXGroupID”, “constact-20100000002”);</p><p><strong>bytesMessage</strong>.setIntProperty(“JMSXGroupSeq”, -1);</p><p>如上图所示，同一个queue中，拥有相同JMSXGroupID的消息将发往同一个消费者，解决顺序问题，不同分组的消息又能被其他消费者并行消费，解决负载均衡的问题。</p><h3 id="RabbitMQ-1"><a href="#RabbitMQ-1" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p>如果有顺序依赖的消息，要保证消息有一个hashKey，类似于数据库表分区的的分区key列。保证对同一个key的消息发送到相同的队列。A用户产生的消息（包括创建消息和删除消息）都按A的hashKey分发到同一个队列。只需要把强相关的两条消息基于相同的路由就行了，也就是说经过m1和m2的在路由表里的路由是一样的，那自然m1会优先于m2去投递。而且一个queue只对应一个consumer。</p><h3 id="Kafka-1"><a href="#Kafka-1" class="headerlink" title="Kafka"></a>Kafka</h3><p>一个topic，一个partition，一个consumer，内部单线程消费</p><h2 id="如何解决消息队列的延时以及过期失效问题？"><a href="#如何解决消息队列的延时以及过期失效问题？" class="headerlink" title="如何解决消息队列的延时以及过期失效问题？"></a>如何解决消息队列的延时以及过期失效问题？</h2><p>rabbitmq，rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间，而又没有设置死信队列机制，就会被rabbitmq给清理掉，这个数据就没了。</p><p>ActiveMQ则通过更改配置，支持消息的定时发送。</p><h2 id="有几百万消息持续积压几小时怎么解决？"><a href="#有几百万消息持续积压几小时怎么解决？" class="headerlink" title="有几百万消息持续积压几小时怎么解决？ "></a>有几百万消息持续积压几小时怎么解决？ </h2><p>发生了线上故障，几千万条数据在MQ里积压很久。是修复consumer的问题，让他恢复消费速度，然后等待几个小时消费完毕？这是个解决方案。不过有时候我们还会进行临时紧急扩容。</p><p>一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条。1000多万条，所以如果积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来。</p><p>一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：</p><p>先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉。</p><p>新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量。然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue。</p><p>接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据。</p><p>这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据。</p><p>等快速消费完积压数据之后，再恢复原先部署架构，重新用原先的consumer机器来消费消息。</p><h2 id="Kafka是如何实现高性能的？"><a href="#Kafka是如何实现高性能的？" class="headerlink" title="Kafka是如何实现高性能的？"></a>Kafka是如何实现高性能的？</h2><h3 id="宏观架构层面利用Partition实现并行处理"><a href="#宏观架构层面利用Partition实现并行处理" class="headerlink" title="宏观架构层面利用Partition实现并行处理"></a>宏观架构层面利用Partition实现并行处理</h3><p>Kafka中每个Topic都包含一个或多个Partition，不同Partition可位于不同节点。同时Partition在物理上对应一个本地文件夹，每个Partition包含一个或多个Segment，每个Segment包含一个数据文件和一个与之对应的索引文件。在逻辑上，可以把一个Partition当作一个非常长的数组，可通过这个“数组”的索引（offset）去访问其数据。</p><p>一方面，由于不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于Partition在物理上对应一个文件夹，即使多个Partition位于同一个节点，也可通过配置让同一节点上的不同Partition置于不同的disk<br>drive上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>利用多磁盘的具体方法是，将不同磁盘mount到不同目录，然后在server.properties中，将log.dirs设置为多目录（用逗号分隔）。Kafka会自动将所有Partition尽可能均匀分配到不同目录也即不同目录（也即不同disk）上。</p><p>Partition是最小并发粒度，Partition个数决定了可能的最大并行度。。</p><h3 id="ISR实现可用性与数据一致性的动态平衡"><a href="#ISR实现可用性与数据一致性的动态平衡" class="headerlink" title="ISR实现可用性与数据一致性的动态平衡"></a>ISR实现可用性与数据一致性的动态平衡</h3><h4 id="常用数据复制及一致性方案"><a href="#常用数据复制及一致性方案" class="headerlink" title="常用数据复制及一致性方案"></a>常用数据复制及一致性方案</h4><h5 id="Master-Slave"><a href="#Master-Slave" class="headerlink" title="Master-Slave"></a>Master-Slave</h5><p>- RDBMS的读写分离即为典型的Master-Slave方案</p><p>- 同步复制可保证强一致性但会影响可用性</p><p>- 异步复制可提供高可用性但会降低一致性</p><h5 id="WNR"><a href="#WNR" class="headerlink" title="WNR"></a>WNR</h5><p>- 主要用于去中心化的分布式系统中。</p><p>-<br>N代表总副本数，W代表每次写操作要保证的最少写成功的副本数，R代表每次读至少要读取的副本数</p><p>- 当W+R&gt;N时，可保证每次读取的数据至少有一个副本拥有最新的数据</p><p>-<br>多个写操作的顺序难以保证，可能导致多副本间的写操作顺序不一致。Dynamo通过向量时钟保证最终一致性</p><h5 id="Paxos及其变种"><a href="#Paxos及其变种" class="headerlink" title="Paxos及其变种"></a>Paxos及其变种</h5><p>- Google的Chubby，Zookeeper的原子广播协议（Zab），RAFT等</p><h4 id="基于ISR的数据复制方案"><a href="#基于ISR的数据复制方案" class="headerlink" title="基于ISR的数据复制方案"></a>基于ISR的数据复制方案</h4><p>Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。从一这点来讲，Kafka的数据复制方案接近于上文所讲的Master-Slave方案。不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。</p><p>ISR，也即In-sync<br>Replica。每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。</p><p>这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。</p><p>由于Leader可移除不能及时与之同步的Follower，故与同步复制相比可避免最慢的Follower拖慢整体速度，也即ISR提高了系统可用性。</p><p>ISR中的所有Follower都包含了所有Commit过的消息，而只有Commit过的消息才会被Consumer消费，故从Consumer的角度而言，ISR中的所有Replica都始终处于同步状态，从而与异步复制方案相比提高了数据一致性。</p><p>ISR可动态调整，极限情况下，可以只包含Leader，极大提高了可容忍的宕机的Follower的数量。与Majority<br>Quorum方案相比，容忍相同个数的节点失败，所要求的总节点数少了近一半。</p><h3 id="具体实现层面高效使用磁盘特性和操作系统特性"><a href="#具体实现层面高效使用磁盘特性和操作系统特性" class="headerlink" title="具体实现层面高效使用磁盘特性和操作系统特性"></a>具体实现层面高效使用磁盘特性和操作系统特性</h3><h4 id="将写磁盘的过程变为顺序写"><a href="#将写磁盘的过程变为顺序写" class="headerlink" title="将写磁盘的过程变为顺序写"></a>将写磁盘的过程变为顺序写</h4><p>Kafka的整个设计中，Partition相当于一个非常长的数组，而Broker接收到的所有消息顺序写入这个大数组中。同时Consumer通过Offset顺序消费这些数据，并且不删除已经消费的数据，从而避免了随机写磁盘的过程。</p><p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统Kafka也没必要保存所有数据，需要删除旧的数据。而这个删除过程，并非通过使用“读-写”模式去修改文件，而是将Partition分为多个Segment，每个Segment对应一个物理文件，通过删除整个文件的方式去删除Partition内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p><p>在存储机制上，使用了Log Structured Merge Trees(LSM) 。</p><p>注：Log Structured Merge Trees(LSM)，谷歌 “BigTable”<br>的论文，中提出，LSM是当前被用在许多产品的文件结构策略：HBase, Cassandra,<br>LevelDB,<br>SQLite,Kafka。LSM被设计来提供比传统的B+树或者ISAM更好的写操作吞吐量，通过消去随机的本地更新操作来达到这个目标。这个问题的本质还是磁盘随机操作慢，顺序读写快。这二种操作存在巨大的差距，无论是磁盘还是SSD，而且快至少三个数量级。</p><h4 id="充分利用Page-Cache"><a href="#充分利用Page-Cache" class="headerlink" title="充分利用Page Cache"></a>充分利用Page Cache</h4><p>使用Page Cache的好处如下</p><p>- I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能</p><p>- I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</p><p>-<br>充分利用所有空闲内存（非JVM内存）。如果使用应用层Cache（即JVM堆内存），会增加GC负担</p><p>- 读操作可直接在Page<br>Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过Page<br>Cache）交换数据</p><p>- 如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用</p><p>Broker收到数据后，写磁盘时只是将数据写入Page<br>Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page<br>Cache内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由Kafka层面的Replication机制去解决。如果为了保证这种情况下数据不丢失而强制将Page<br>Cache中的数据Flush到磁盘，反而会降低性能。也正因如此，Kafka虽然提供了flush.messages和flush.ms两个参数将Page<br>Cache中的数据强制Flush到磁盘，但是Kafka并不建议使用。</p><p>如果数据消费速度与生产速度相当，甚至不需要通过物理磁盘交换数据，而是直接通过Page<br>Cache交换数据。同时，Follower从Leader Fetch数据时，也可通过Page Cache完成。</p><p>注：Page Cache，又称pcache，其中文名称为页高速缓冲存储器，简称页高缓。page<br>cache的大小为一页，通常为4K。在linux读写文件时，它用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问。 是Linux操作系统的一个特色。</p><h4 id="支持多Disk-Drive"><a href="#支持多Disk-Drive" class="headerlink" title="支持多Disk Drive"></a>支持多Disk Drive</h4><p>Broker的log.dirs配置项，允许配置多个文件夹。如果机器上有多个Disk<br>Drive，可将不同的Disk挂载到不同的目录，然后将这些目录都配置到log.dirs里。Kafka会尽可能将不同的Partition分配到不同的目录，也即不同的Disk上，从而充分利用了多Disk的优势。</p><h4 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h4><p>Kafka中存在大量的网络数据持久化到磁盘（Producer到Broker）和磁盘文件通过网络发送（Broker到Consumer）的过程。这一过程的性能直接影响Kafka的整体吞吐量。</p><p>传统模式下的四次拷贝与四次上下文切换</p><p>以将磁盘文件通过网络发送为例。传统模式下，一般使用如下伪代码所示的方法先将文件数据读入内存，然后通过Socket将内存中的数据发送出去。</p><p>buffer = File.readSocket.send(buffer)</p><p>这一过程实际上发生了四次数据拷贝。首先通过系统调用将文件数据读入到内核态Buffer（DMA拷贝），然后应用程序将内存态Buffer数据读入到用户态Buffer（CPU拷贝），接着用户程序通过Socket发送数据时将用户态Buffer数据拷贝到内核态Buffer（CPU拷贝），最后通过DMA拷贝将数据拷贝到NIC<br>Buffer。同时，还伴随着四次上下文切换。</p><p>而Linux<br>2.4+内核通过sendfile系统调用，提供了零拷贝。数据通过DMA拷贝到内核态Buffer后，直接通过DMA拷贝到NIC<br>Buffer，无需CPU拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个sendfile调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p><p>从具体实现来看，Kafka的数据传输通过Java<br>NIO的FileChannel的transferTo和transferFrom方法实现零拷贝。</p><p>注：<br>transferTo和transferFrom并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，如果操作系统提供sendfile这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。</p><h4 id="减少网络开销批处理"><a href="#减少网络开销批处理" class="headerlink" title="减少网络开销批处理"></a>减少网络开销批处理</h4><p>批处理是一种常用的用于提高I/O性能的方式。对Kafka而言，批处理既减少了网络传输的Overhead，又提高了写磁盘的效率。</p><p>Kafka<br>的send方法并非立即将消息发送出去，而是通过batch.size和linger.ms控制实际发送频率，从而实现批量发送。</p><p>由于每次网络传输，除了传输消息本身以外，还要传输非常多的网络协议本身的一些内容（称为Overhead），所以将多条消息合并到一起传输，可有效减少网络传输的Overhead，进而提高了传输效率。</p><h4 id="数据压缩降低网络负载"><a href="#数据压缩降低网络负载" class="headerlink" title="数据压缩降低网络负载"></a>数据压缩降低网络负载</h4><p>Kafka从0.7开始，即支持将数据压缩后再传输给Broker。除了可以将每条消息单独压缩然后传输外，Kafka还支持在批量发送时，将整个Batch的消息一起压缩后传输。数据压缩的一个基本原理是，重复数据越多压缩效果越好。因此将整个Batch的数据一起压缩能更大幅度减小数据量，从而更大程度提高网络传输效率。</p><p>Broker接收消息后，并不直接解压缩，而是直接将消息以压缩后的形式持久化到磁盘。Consumer<br>Fetch到数据后再解压缩。因此Kafka的压缩不仅减少了Producer到Broker的网络传输负载，同时也降低了Broker磁盘操作的负载，也降低了Consumer与Broker间的网络传输量，从而极大得提高了传输效率，提高了吞吐量。</p><h4 id="高效的序列化方式"><a href="#高效的序列化方式" class="headerlink" title="高效的序列化方式"></a>高效的序列化方式</h4><p>Kafka消息的Key和Payload（或者说Value）的类型可自定义，只需同时提供相应的序列化器和反序列化器即可。因此用户可以通过使用快速且紧凑的序列化-反序列化方式（如Avro，Protocal<br>Buffer）来减少实际网络传输和磁盘存储的数据规模，从而提高吞吐率。这里要注意，如果使用的序列化方法太慢，即使压缩比非常高，最终的效率也不一定高。</p><p><a href="https://blog.csdn.net/wugenqiang/article/details/88609066" target="_blank" rel="noopener">https://blog.csdn.net/wugenqiang/article/details/88609066</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;

&lt;h2 id=&quot;为什么使用消息队列？&quot;&gt;&lt;a href=&quot;#为什么使用消息队列？&quot; class=&quot;headerlink&quot; title=&quot;为什么使用消息队列？ &quot;&gt;&lt;/a&gt;为什么使用消息队列？ &lt;/h2&gt;&lt;p&gt;其实就是问问你消息队列都有哪些使用场景，然后
      
    
    </summary>
    
    
      <category term="消息中间件常见面试题" scheme="https://hicker000.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
    
  </entry>
  
  <entry>
    <title>什么是消息中间件？</title>
    <link href="https://hicker000.github.io/2020/02/25/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%9F/"/>
    <id>https://hicker000.github.io/2020/02/25/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%9F/</id>
    <published>2020-02-25T01:49:00.000Z</published>
    <updated>2020-02-25T13:31:31.316Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是消息中间件？"><a href="#什么是消息中间件？" class="headerlink" title="什么是消息中间件？"></a>什么是消息中间件？</h1><!-- toc --><h2 id="消息中间件-MQ-的定义"><a href="#消息中间件-MQ-的定义" class="headerlink" title="消息中间件(MQ)的定义"></a>消息中间件(MQ)的定义</h2><p>其实并没有标准定义。一般认为，消息中间件属于分布式系统中一个子系统，关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。</p><p><img src="img%5Cimage-20200225144411023.png" alt="image-20200225144411023"></p><p><img src="E:images%5Cimage-20200225140502618-1582610711570.png" alt="image-20200225140502618"></p><h2 id="为什么要用消息中间件？"><a href="#为什么要用消息中间件？" class="headerlink" title="为什么要用消息中间件？"></a>为什么要用消息中间件？</h2><p>假设一个电商交易的场景，用户下单之后调用库存系统减库存，然后需要调用物流系统进行发货，如果交易、库存、物流是属于一个系统的，那么就是接口调用。但是随着系统的发展，各个模块越来越庞大、业务逻辑越来越复杂，必然是要做服务化和业务拆分的。这个时候就需要考虑这些系统之间如何交互，第一反应就是RPC（Remote<br>Procedure<br>Call）。系统继续发展，可能一笔交易后续需要调用几十个接口来执行业务，比如还有风控系统、短信服务等等。这个时候就需要消息中间件登场来解决问题了。</p><p>所以消息中间件主要解决分布式系统之间消息的传递，同时为分布式系统中其他子系统提供了伸缩性和扩展性。为系统带来了：</p><ul><li><strong>低耦合</strong>，不管是程序还是模块之间，使用消息中间件进行间接通信。</li><li><strong>异步通信能力</strong>，使得子系统之间得以充分执行自己的逻辑而无需等待。</li><li><strong>缓冲能力</strong>，消息中间件像是一个巨大的蓄水池，将高峰期大量的请求存储下来慢慢交给后台进行处理，对于秒杀业务来说尤为重要。</li></ul><p><strong>名称解释</strong>：</p><ul><li><strong>伸缩性:</strong>，是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。就像弹簧一样挂东西一样，用户多，伸一点，用户少，浅一点，啊，不对，缩一点。是伸缩，不是深浅。衡量架构是否高伸缩性的主要标准就是是否可用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。*</li><li><strong>扩展性:</strong>，主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。比如用户购买电影票的应用，现在我们要增加一个功能，用户买了铁血战士的票后，随机抽取用户送异形的限量周边。怎么做到不改动用户购票功能的基础上增加这个功能。熟悉设计模式的同学，应该很眼熟，这是设计模式中的开闭原则（对扩展开放，对修改关闭）在架构层面的一个原则。*</li></ul><h2 id="和RPC有何区别？"><a href="#和RPC有何区别？" class="headerlink" title="和RPC有何区别？"></a>和RPC有何区别？</h2><p>RPC和消息中间件的场景的差异很大程度上在于就是“依赖性”和“同步性”。</p><ul><li>比如短信通知服务并不是事交易环节必须的，并不影响下单流程，不是强依赖，所以交易系统不应该依赖短信服务。比如一些数据分析程序可能需要在拿到一天的总销售量，这个就只需要销售中心提供接口在需要时调用即可。</li><li>消息中间件出现以后对于交易场景可能是调用库存中心等强依赖系统执行业务，之后发布一条消息（这条消息存储于消息中间件中）。像是短信通知服务、数据统计服务等等都是依赖于消息中间件去消费这条消息来完成自己的业务逻辑。</li><li><font color="red">RPC方式是典型的同步方式，让远程调用像本地调用。消息中间件方式属于异步方式。<strong>消息队列是系统级、模块级的通信。RPC是对象级、函数级通信。</strong></font></li></ul><p><strong>相同点:</strong> 都是分布式下面的通信方式。</p><h2 id="消息中间件有些什么使用场景？"><a href="#消息中间件有些什么使用场景？" class="headerlink" title="消息中间件有些什么使用场景？"></a>消息中间件有些什么使用场景？</h2><h3 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h3><p>场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种1.串行的方式；2.并行方式。</p><p>(1) <strong>串行方式</strong>：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</p><p><img src="D92FE5068C4E411A9740F27F480521DC" alt="image"></p><p>(2)<strong>并行方式</strong>：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。</p><p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。</p><p><img src="EF3E2B155D6B41E68552FC08563C66F7" alt="image"></p><p><strong>小结</strong>：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？</p><p>引入消息队列，将不是必须的业务逻辑，异步处理。</p><p><img src="8AB460684DB3406DB06FD4E9E39F85D7" alt="image"></p><p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20<br>QPS。比串行提高了3倍，比并行提高了两倍。</p><h3 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h3><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。</p><p><strong>传统模式的缺点</strong>：</p><ul><li>1） 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；</li><li>2） 订单系统与库存系统耦合；</li></ul><p><img src="A7EFCEDEAFBE4B43BFA5F6C2A9FECBC0" alt="image"></p><p>如何解决以上问题呢？引入应用消息队列后的方案</p><p>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。</p><p>库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</p><p><img src="69AD47A4A43E4EB69962FE709ED2DA80" alt="image"></p><p><strong>假如</strong>：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</p><h3 id="流量削峰"><a href="#流量削峰" class="headerlink" title="流量削峰"></a>流量削峰</h3><p>流量削峰也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p><p><strong>应用场景</strong>：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列：可以控制活动的人数；可以缓解短时间内高流量压垮应用。</p><p><img src="CA3E68D1A5FC40499746A88D55F16B63" alt="image"></p><p>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；秒杀业务根据消息队列中的请求信息，再做后续处理。</p><h3 id="日志处理"><a href="#日志处理" class="headerlink" title="日志处理"></a>日志处理</h3><p>日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下：</p><p><img src="5F7B30CA9DD7425DB3F3240C112ACB4A" alt="image"></p><p>日志采集客户端，负责日志数据采集，定时写入Kafka队列：Kafka消息队列，负责日志数据的接收，存储和转发；日志处理应用：订阅并消费kafka队列中的日志数据；</p><h3 id="消息通讯"><a href="#消息通讯" class="headerlink" title="消息通讯"></a>消息通讯</h3><p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</p><ul><li><strong>点对点通讯</strong>：客户端A和客户端B使用同一队列，进行消息通讯。</li><li><strong>聊天室通讯</strong>：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</li></ul><h2 id="消息中间件的编年史"><a href="#消息中间件的编年史" class="headerlink" title="消息中间件的编年史 "></a>消息中间件的编年史 </h2><p><img src="54FABC73987645D891DF50A715706457" alt="image"></p><p>卡夫卡与法国作家马塞尔·普鲁斯特，爱尔兰作家詹姆斯·乔伊斯并称为西方现代主义文学的先驱和大师。《变形记》是卡夫卡的短篇代表作，是卡夫卡的艺术成就中的一座高峰，被认为是20世纪最伟大的小说作品之一。</p><h2 id="常见的消息中间件比较"><a href="#常见的消息中间件比较" class="headerlink" title="常见的消息中间件比较 "></a>常见的消息中间件比较 </h2><p><img src="928587A370774B53B647863BB36F2695" alt="image"></p><p>如果一般的业务系统要引入MQ，怎么选型：</p><ul><li>用户访问量在ActiveMQ的可承受范围内，而且确实主要是基于解耦和异步来用的，可以考虑ActiveMQ，也比较贴近Java工程师的使用习惯。</li><li>RabbitMQ，但是确实erlang语言阻止了我们去深入研究和掌控，对公司而言，几乎处于不可控的状态，但是确实是开源的，有比较稳定的支持，活跃度也高。</li><li>对自己公司技术实力有绝对自信的，可以用RocketMQ 。</li><li>所以中小型公司，技术实力较为一般，技术挑战不是特别高，用ActiveMQ、RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择</li><li>如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高，几乎是全世界这个领域的事实性规范。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;什么是消息中间件？&quot;&gt;&lt;a href=&quot;#什么是消息中间件？&quot; class=&quot;headerlink&quot; title=&quot;什么是消息中间件？&quot;&gt;&lt;/a&gt;什么是消息中间件？&lt;/h1&gt;&lt;!-- toc --&gt;




&lt;h2 id=&quot;消息中间件-MQ-的定义&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
      <category term="消息中间件" scheme="https://hicker000.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="中间件" scheme="https://hicker000.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>nginx基础</title>
    <link href="https://hicker000.github.io/2019/11/25/nginx%E5%9F%BA%E7%A1%80/"/>
    <id>https://hicker000.github.io/2019/11/25/nginx%E5%9F%BA%E7%A1%80/</id>
    <published>2019-11-25T09:00:50.000Z</published>
    <updated>2020-02-25T14:46:23.039Z</updated>
    
    <content type="html"><![CDATA[<h1 id="nginx基础"><a href="#nginx基础" class="headerlink" title="nginx基础"></a>nginx基础</h1><ul><li><a href="#1">一、Nginx简介</a></li><li><a href="#2">二，Nginx架构设计</a></li><li><a href="#3">三、nginx安装</a></li><li><a href="#4">四、文件结构以及模型概念</a></li><li><a href="#5">五、Nginx日志</a></li></ul><hr><h2 id="一，Nginx简介"><a href="#一，Nginx简介" class="headerlink" title="一，Nginx简介"></a><span id="1">一，Nginx简介</h2><p><strong>Apache</strong></p><p>Apache仍然是时长占用量最高的web服务器，据最新数据统计，市场占有率目前是50%左右。主要优势在于一个是比较早出现的一个Http静态资源服务器，同时又是开源的。所以在技术上的支持以及市面上的各种解决方案都比较成熟。Apache支持的模块非常丰富。</p><p><strong>Nginx</strong></p><p>Nginx是俄罗斯人编写的一款高性能的HTTP和反向代理服务器，在高连接并发的情况下，它能够支持高达50000个并发连接数的响应，但是内存、CPU等系统资源消耗却很低，运行很稳定。目前Nginx在国内很多大型企业都有应用，据最新统计，Nginx的市场占有率已经到33%左右了。而Apache的市场占有率虽然仍然是最高的，但是是呈下降趋势。而Nginx的势头很明显。选择Nginx的理由也很简单：第一，它可以支持5W高并发连接；第二，内存消耗少；第三，成本低，如果采用F5、NetScaler等硬件负载均衡设备的话，需要大几十万。而Nginx是开源的，可以免费使用并且能用于商业用途</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、占有内存少，并发能力强，Nginx的并发能力在同类型的网页服务器中表现较好。</p><p>2、Nginx相较于Apache\lighttpd具有占有内存少</p><p>3、稳定性高等优势，并且依靠并发能力强</p><p>4、有丰富的模块库以及友好灵活的配置</p><p>5、支持热部署。即可以在7×24小时不间断服务的前提下，升级Nginx的可执行文件。当然，它也支持不停止服务就更新配置项、更换日志文件等功能。</p><p>6、可以做反向代理，并且可以支持七层负载均衡</p><h3 id="架构中的作用"><a href="#架构中的作用" class="headerlink" title="架构中的作用"></a><strong>架构中的作用</strong></h3><p><strong>介绍nginx在系统架构（网关入口）中的作用，总结如下：</strong></p><p>1、路由功能（与微服务对应）：域名/路径，进行路由选择后台服务器</p><p>2、负载功能（与高并发高可用对应）：对后台服务器集群进行负载</p><p>3、静态服务器（比tomcat性能高很多）：在mvvm模式中，充当文件读取职责</p><p>总结：实际使用中，这三项功用，会混合使用。比如先分离动静，再路由服务，再负载机器</p><h3 id="正向代理与反向代理"><a href="#正向代理与反向代理" class="headerlink" title="正向代理与反向代理"></a>正向代理与反向代理</h3><p>1、<strong>代理</strong>：意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。</p><p><img src="5FB528CD197C4970A0F9249E8D78ABD1" alt="image"></p><p>比如代理律师，代购，政府机关办事的代理人等等。</p><p>2、<strong>反向代理</strong>（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</p><p><img src="77BEA255FC8448D7856E613B2DF6AFE9" alt="image"></p><hr><h2 id="二，Nginx架构设计"><a href="#二，Nginx架构设计" class="headerlink" title="二，Nginx架构设计"></a><span id="2">二，Nginx架构设计</h2><h3 id="2-1。-Nginx的模块化设计"><a href="#2-1。-Nginx的模块化设计" class="headerlink" title="2.1。 Nginx的模块化设计"></a>2.1。 Nginx的模块化设计</h3><p>高度模块化的设计是 Nginx 的架构基础。Nginx<br>服务器被分解为多个模块，每个模块就是一个功能模块，只负责自身的功能，模块之间严格遵循“高内聚，低耦合”的原则。</p><p><img src="B2CEA77953F347E096947D224D64249E" alt="image"></p><ul><li><strong>核心模块</strong></li></ul><p>核心模块是 Nginx<br>服务器正常运行必不可少的模块，提供错误日志记录、配置文件解析、事件驱动机制、进程管理等核心功能。</p><ul><li><strong>标准 HTTP 模块</strong></li></ul><p>标准 HTTP 模块提供 HTTP 协议解析相关的功能，如：端口配置、网页编码设置、HTTP<br>响应头设置等。</p><ul><li><strong>可选 HTTP 模块</strong></li></ul><p>可选 HTTP 模块主要用于扩展标准的 HTTP 功能，让 Nginx<br>能处理一些特殊的服务，如：Flash 多媒体传输、解析 GeoIP 请求、SSL 支持等。</p><ul><li><strong>邮件服务模块</strong></li></ul><p>邮件服务模块主要用于支持 Nginx 的邮件服务，包括对 POP3 协议、IMAP 协议和 SMTP<br>协议的支持。</p><ul><li><strong>第三方模块</strong></li></ul><p>第三方模块是为了扩展 Nginx 服务器应用，完成开发者自定义功能，如：Json 支持、Lua<br>支持等。</p><h3 id="2-2-Nginx多进程模型"><a href="#2-2-Nginx多进程模型" class="headerlink" title="2.2. Nginx多进程模型"></a>2.2. Nginx多进程模型</h3><hr><p><img src="3BC567D4CE694097922BD4226ECC1983" alt="image"></p><p>1、服务器每当收到一个客户端时。就有服务器主进程（master<br>process）生成一个子进程（worker<br>process）出来和客户端建立连接进行交互，直到连接断开，该子进程结束。</p><p>2、使用进程的好处是各个进程之间相互独立，不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。</p><p>其次，采用独立的进程，可以让进程互相之间不会影响，如果一个进程发生异常退出时，其它进程正常工作，master<br>进程则很快启动新的 worker 进程，确保服务不中断，将风险降到最低。</p><p>缺点是操作系统生成一个子进程需要进行内存复制等操作，在资源和时间上会产生一定的开销；当有大量请求时，会导致系统性能下降。</p><h3 id="2-3-Nginx的epoll模式"><a href="#2-3-Nginx的epoll模式" class="headerlink" title="2.3. Nginx的epoll模式"></a>2.3. Nginx的epoll模式</h3><p><img src="EB3C80B075DB4ADE8F35DB7B6E011F32" alt="image"></p><p>select和poll的处理模式如上图：</p><p>–在某一时刻，进程收集所有的连接，其实这100万连接中大部分是没有事件发生的。因此，如果每次收集事件时，都把这100万连接的套接字传给操作系统（这首先就是用户态内存到内核内存的大量复制），而由操作系统内核寻找这些链接上没有处理的事件，将会是巨大的浪费。</p><p>而epoll改进了收集连接的动作，提高效率。</p><p><strong>epoll的优点：</strong></p><ul><li><p>支持一个进程打开大数目的socket描述符(FD)</p></li><li><p>IO效率不随FD数目增加而线性下降</p></li><li><p>使用mmap加速内核与用户空间的消息传递</p></li></ul><h2 id="三，nginx安装："><a href="#三，nginx安装：" class="headerlink" title="三，nginx安装："></a><span id="3">三，nginx安装：</h2><h3 id="3-1-源码编译方式"><a href="#3-1-源码编译方式" class="headerlink" title="3.1. 源码编译方式"></a>3.1. 源码编译方式</h3><p>安装make：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install autoconf automake make</span><br></pre></td></tr></table></figure><p>安装g++: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc gcc-c++</span><br></pre></td></tr></table></figure><p>一般系统中已经装了了make和g++，无须再装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum -y install pcre pcre-devel</span><br><span class="line"></span><br><span class="line">yum -y install zlib zlib-devel</span><br><span class="line"></span><br><span class="line">yum install -y openssl openssl-devel</span><br></pre></td></tr></table></figure><p>安装nginx依赖的库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wget http://nginx.org/download/nginx-1.9.15.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf nginx-1.9.15.tar.gz</span><br><span class="line"></span><br><span class="line">cd nginx-1.9.15</span><br><span class="line"></span><br><span class="line">./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p><strong>配置</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--prefix指定安装目录</span><br><span class="line"></span><br><span class="line">--with-http_ssl_module安装https模块</span><br><span class="line"></span><br><span class="line">creating objs/Makefile 代表编译成功</span><br><span class="line"></span><br><span class="line">make编译</span><br><span class="line"></span><br><span class="line">make install安装</span><br></pre></td></tr></table></figure><h3 id="3-2-yum方式："><a href="#3-2-yum方式：" class="headerlink" title="3.2. yum方式："></a>3.2. <strong>yum方式：</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">centos6：yum install epel-release -y \#yum扩展源</span><br><span class="line"></span><br><span class="line">yum install nginx -y</span><br></pre></td></tr></table></figure><hr><h2 id="四，文件结构以及模型概念："><a href="#四，文件结构以及模型概念：" class="headerlink" title="四，文件结构以及模型概念："></a><span id="4">四，文件结构以及模型概念：</h2><h3 id="4-1-目录结构"><a href="#4-1-目录结构" class="headerlink" title="4.1. 目录结构"></a>4.1. 目录结构</h3><ul><li><strong>Conf 配置文件</strong></li><li><strong>Html 网页文件</strong></li><li><strong>Logs 日志文件</strong></li><li><strong>Sbin 二进制程序</strong></li></ul><p><strong>启停命令：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./nginx -c nginx.conf的文件。如果不指定，默认为NGINX_HOME/conf/nginx.conf</span><br><span class="line"></span><br><span class="line">./nginx -s stop 停止</span><br><span class="line"></span><br><span class="line">./nginx -s quit退出</span><br><span class="line"></span><br><span class="line">./nginx -s reload 重新加载nginx.conf</span><br><span class="line"></span><br><span class="line">./nginx -t 检查配置文件是否正确</span><br></pre></td></tr></table></figure><p><strong>发送信号的方式</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kill -QUIT 进程号 安全停止</span><br><span class="line"></span><br><span class="line">kil -TERM 进程号 立即停止</span><br></pre></td></tr></table></figure><h3 id="4-2-nginx模型概念："><a href="#4-2-nginx模型概念：" class="headerlink" title="4.2. nginx模型概念："></a>4.2. nginx模型概念：</h3><p><strong>Nginx会按需同时运行多个进程：</strong></p><p><img src="BAB3479FD5F54DBBBB5C71A811F53F96" alt="image"></p><p>一个主进程(master)和几个工作进程(worker)，配置了缓存时还会有缓存加载器进程(cache<br>loader)和缓存管理器进程(cache manager)等。</p><p>所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。</p><p>主进程以root用户身份运行，而worker、cache loader和cache<br>manager均应以非特权用户身份（user配置项）运行。</p><p><strong>主进程主要完成如下工作：</strong></p><ol><li>读取并验正配置信息；</li><li>创建、绑定及关闭套接字；</li><li>启动、终止及维护worker进程的个数；</li><li>无须中止服务而重新配置工作特性；</li><li>重新打开日志文件；</li></ol><p><strong>worker进程主要完成的任务包括：</strong></p><ol><li>接收、传入并处理来自客户端的连接；</li><li>提供反向代理及过滤功能；</li><li>nginx任何能完成的其它任务；</li></ol><h3 id="4-3-nginx-conf配置文件结构"><a href="#4-3-nginx-conf配置文件结构" class="headerlink" title="4.3. nginx.conf配置文件结构"></a>4.3. nginx.conf配置文件结构</h3><p><img src="498BFE42F9F34978891B411C4F115E22" alt="image"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#user nobody; #主模块命令，</span><br><span class="line">指定Nginx的worker进程运行用户以及用户组，默认由nobody账号运行。</span><br><span class="line"></span><br><span class="line">worker_processes 1;  #指定Nginx要开启的进程数。  根据硬件调整，通常等于CPU数量或者2倍于CPU。</span><br><span class="line"></span><br><span class="line">worker_rlimit_nofile 100000; #worker进程的最大打开文件数限制</span><br><span class="line"></span><br><span class="line">#error_log logs/error.log;</span><br><span class="line"></span><br><span class="line">#error_log logs/error.log notice;</span><br><span class="line"></span><br><span class="line">#error_log logs/error.log info;</span><br><span class="line"></span><br><span class="line">#pid logs/nginx.pid;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line"></span><br><span class="line">use epoll;</span><br><span class="line"></span><br><span class="line">worker_connections 1024;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>以上这块配置代码是对nginx全局属性的配置。</strong></p><p><strong>user</strong> :主模块命令，<br>指定Nginx的worker进程运行用户以及用户组，默认由nobody账号运行。</p><p><strong>worker_processes</strong>: 指定Nginx要开启的进程数。</p><p><strong>error log</strong>:用来定义全局错设日志文件的路径和日志名称。</p><blockquote><p>日志输出级别有debug，info，notice，warn，error，crit<br>可供选择，其中debug输出日志最为详细，面crit（严重）输出日志最少。默认是error</p></blockquote><p><strong>pid</strong>: 用来指定进程id的存储文件位置。</p><p><strong>event</strong>：设定nginx的工作模式及连接数上限，</p><blockquote><p>其中参数use用来指定nginx的工作模式（这里是epoll，epoll是多路复用IO(I/O<br>Multiplexing)中的一种方式）,</p></blockquote><blockquote><p>nginx支持的工作模式有select ,poll,kqueue,epoll,rtsig,/dev/poll。</p></blockquote><blockquote><p>其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，对于linux系统，epoll是首选。</p></blockquote><p><strong>worker_connection</strong> : 是设置nginx每个进程最大的连接数，默认是1024，所以nginx最大的连接数max_client=worker_processes * worker_connections。</p><blockquote><p>进程最大连接数受到系统最大打开文件数的限制，需要设置ulimit。</p></blockquote><p><strong>下面部分是nginx对http服务器相关属性的设置</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    include       mime.types;               主模块命令，对配置文件所包含文件的设定，减少主配置文件的复杂度，相当于把部分设置放在别的地方，然后在包含进来，保持主配置文件的简洁</span><br><span class="line">    default_type  application/octet-stream; 默认文件类型，当文件类型未定义时候就使用这类设置的。</span><br><span class="line"></span><br><span class="line">    #log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;   指定nginx日志的格式</span><br><span class="line">    #                  &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">    #                  &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    #access_log  logs/access.log  main;</span><br><span class="line">    sendfile        on;   开启高效文件传输模式（zero copy 方式），避免内核缓冲区数据和用户缓冲区数据之间的拷贝。</span><br><span class="line">    #tcp_nopush     on;  开启TCP_NOPUSH套接字（sendfile开启时有用）</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;   客户端连接超时时间</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;             设置是否开启gzip模块</span><br></pre></td></tr></table></figure><p><strong>下面是server段虚拟主机的配置</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen       80;   虚拟主机的服务端口</span><br><span class="line">        server_name  localhost;   用来指定ip或者域名，多个域名用逗号分开</span><br><span class="line">        #charset koi8-r;</span><br><span class="line">        location / &#123;        </span><br><span class="line">               #地址匹配设置，支持正则匹配，也支持条件匹配，这里是默认请求地址，用户可以location命令对nginx进行动态和静态网页过滤处理</span><br><span class="line">            root   html;                   虚拟主机的网页根目录</span><br><span class="line">            index  index.html index.htm;   默认访问首页文件</span><br><span class="line">        &#125;</span><br><span class="line">        #error_page  404              /404.html;</span><br><span class="line">        # redirect server error pages to the static page /50x.html        </span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="五，Nginx日志"><a href="#五，Nginx日志" class="headerlink" title="五，Nginx日志"></a><span id="5">五，Nginx日志</h3><p>通过访问日志，你可以得到用户地域来源、跳转来源、使用终端、某个URL访问量等相关信息；通过错误日志，你可以得到系统某个服务或server的性能瓶颈等。因此，将日志好好利用，你可以得到很多有价值的信息。 </p><p><strong>日志格式</strong></p><p>打开nginx.conf配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/nginx/conf/nginx.conf</span><br></pre></td></tr></table></figure><p>日志部分内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#access_log logs/access.log main;</span><br></pre></td></tr></table></figure><blockquote><p>日志生成的到Nginx根目录logs/access.log文件，默认使用“main”日志格式，也可以自定义格式。</p></blockquote><p><strong>默认“main”日志格式：</strong> 参数明细表：</p><table><thead><tr><th>$remote_addr</th><th>客户端的ip地址(代理服务器，显示代理服务ip)</th></tr></thead><tbody><tr><td>$remote_user</td><td>用于记录远程客户端的用户名称（一般为“-”）</td></tr><tr><td>$time_local</td><td>用于记录访问时间和时区</td></tr><tr><td>$request</td><td>用于记录请求的url以及请求方法</td></tr><tr><td>$status</td><td>响应状态码，例如：200成功、404页面找不到等。</td></tr><tr><td>$body_bytes_sent</td><td>给客户端发送的文件主体内容字节数</td></tr><tr><td>$http_user_agent</td><td>用户所使用的代理（一般为浏览器）</td></tr><tr><td>$http_x_forwarded_for</td><td>可以记录客户端IP，通过代理服务器来记录客户端的ip地址</td></tr><tr><td>$http_referer</td><td>可以记录用户是从哪个链接访问过来的</td></tr></tbody></table><p>查看日志命令tail -f /usr/local/nginx/logs/access.log</p><p><strong>日志配置和及切割</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/rsyslog start #系统日志，如不开启，看不到定时任务日志</span><br><span class="line"></span><br><span class="line">/etc/rc.d/init.d/crond start #定时任务开启</span><br></pre></td></tr></table></figure><p><strong>编写sh：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># 指定日志和切割后日志备份的目录</span><br><span class="line">YEAR=$(date +%Y)</span><br><span class="line">MONTH=$(date +%m)</span><br><span class="line">DAY=$(date +%d)</span><br><span class="line">YESTERDAY=$(date -d &quot;yesterday&quot; +%Y-%m-%d)</span><br><span class="line">LOGS_PATH=/data/nginx/logs</span><br><span class="line">LOGS_BAK_PATH=/data/nginx/logs-bak</span><br><span class="line"></span><br><span class="line"># 得到1级目录名</span><br><span class="line">if [[ $(($DAY)) -eq 1 ]]</span><br><span class="line">  then</span><br><span class="line">    if [[ $(($MONTH)) -eq 1 ]]</span><br><span class="line">      then</span><br><span class="line">        LOGS_BAK_PATH=$LOGS_BAK_PATH/$(($&#123;YEAR&#125;-1))-12</span><br><span class="line">    else</span><br><span class="line">      if [[ $(($MONTH)) -gt 10 ]]</span><br><span class="line">        then</span><br><span class="line">          LOGS_BAK_PATH=$LOGS_BAK_PATH/$&#123;YEAR&#125;-$(($&#123;MONTH&#125;-1))</span><br><span class="line">      else</span><br><span class="line">          LOGS_BAK_PATH=$LOGS_BAK_PATH/$&#123;YEAR&#125;-0$(($&#123;MONTH&#125;-1))</span><br><span class="line">      fi</span><br><span class="line">    fi</span><br><span class="line">else</span><br><span class="line">    LOGS_BAK_PATH=$LOGS_BAK_PATH/$&#123;YEAR&#125;-$&#123;MONTH&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 创建目录</span><br><span class="line">mkdir -p $LOGS_BAK_PATH/$&#123;YESTERDAY&#125;</span><br><span class="line"></span><br><span class="line"># 复制当前的日志文件到备份的目录</span><br><span class="line">cp $&#123;LOGS_PATH&#125;/access.log $&#123;LOGS_BAK_PATH&#125;/$&#123;YESTERDAY&#125;/access_$&#123;YESTERDAY&#125;.</span><br><span class="line">log#cp $&#123;LOGS_PATH&#125;/admin_access.log $&#123;LOGS_BAK_PATH&#125;/$&#123;YESTERDAY&#125;/admin_access_</span><br><span class="line">$&#123;YESTERDAY&#125;.logcp $&#123;LOGS_PATH&#125;/error.log $&#123;LOGS_BAK_PATH&#125;/$&#123;YESTERDAY&#125;/error_$&#123;YESTERDAY&#125;.lo</span><br><span class="line">g</span><br><span class="line"># 清空日志</span><br><span class="line">&gt; $&#123;LOGS_PATH&#125;/access.log</span><br><span class="line">#&gt; $&#123;LOGS_PATH&#125;/admin_access.log</span><br><span class="line">&gt; $&#123;LOGS_PATH&#125;/error.log</span><br></pre></td></tr></table></figure><p><strong>配置cron：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * /usr/local/nginx/sbin/logcut.sh</span><br></pre></td></tr></table></figure><p><strong>拓展</strong></p><blockquote><p>kill命令格式：<br>kill 是向进程发送信号的命令。<br>Nginx的信号<br>1）、TERM、INT 快速关闭；<br>2）、QUIT从容关闭；<br>3）、HUP平滑重启，重新加载配置文件；<br>4）、USR1 重新打开日志文件；<br>5）、USR2 平滑升级可执行程序；<br>KILL 9 强制终止，直接杀</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;nginx基础&quot;&gt;&lt;a href=&quot;#nginx基础&quot; class=&quot;headerlink&quot; title=&quot;nginx基础&quot;&gt;&lt;/a&gt;nginx基础&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1&quot;&gt;一、Nginx简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=
      
    
    </summary>
    
    
      <category term="分布式专题" scheme="https://hicker000.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="Nginx" scheme="https://hicker000.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot Actuator监控端点</title>
    <link href="https://hicker000.github.io/2019/11/10/Spring-Boot-Actuator%E7%9B%91%E6%8E%A7%E7%AB%AF%E7%82%B9/"/>
    <id>https://hicker000.github.io/2019/11/10/Spring-Boot-Actuator%E7%9B%91%E6%8E%A7%E7%AB%AF%E7%82%B9/</id>
    <published>2019-11-10T09:25:45.000Z</published>
    <updated>2019-11-10T09:29:21.369Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spring-Boot-Actuator监控端点"><a href="#Spring-Boot-Actuator监控端点" class="headerlink" title="Spring Boot Actuator监控端点"></a>Spring Boot Actuator监控端点</h2><ul><li><a href="#1">一,初识Actuator</a></li><li><a href="#2">二,原生端点</a><ul><li><a href="#2.1">2.1 应用配置类</a><ul><li><a href="#2.1.1">autoconfig</a></li><li><a href="#2.1.2">beans</a></li><li><a href="#2.1.3">configprops</a></li><li><a href="#2.1.4">env</a></li><li><a href="#2.1.5">mappings</a></li><li><a href="#2.1.6">info</a></li></ul></li><li><a href="#2.2">2.2 度量指标类</a><ul><li><a href="#2.2.1">metrics</a></li><li><a href="#2.2.2">health</a></li><li><a href="#2.2.3">dump</a></li><li><a href="#2.2.4">trace</a></li></ul></li><li><a href="#2.3">2.3 操作控制类</a></li></ul></li></ul><p>在Spring Boot的众多Starter POMs中有一个特殊的模块，它不同于其他模块那样大多用于开发业务功能或是连接一些其他外部资源。它完全是一个用于暴露自身信息的模块，所以很明显，它的主要作用是用于监控与管理，它就是：spring-boot-starter-actuator。</p><h2 id="一-初识Actuator"><a href="#一-初识Actuator" class="headerlink" title="一,初识Actuator"></a><span id="1">一,初识Actuator</h2><p>下面，我们可以通过对快速入门中实现的Spring Boot应用增加spring-boot-starter-actuator模块功能，来对它有一个直观的认识。</p><p>在现有的Spring Boot应用中引入该模块非常简单，只需要在pom.xml的dependencies节点中，新增spring-boot-starter-actuator的依赖即可，具体如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>通过增加该依赖之后，重新启动应用。此时，我们可以在控制台中看到如下图所示的输出：</p><p><img src="B73FD621480E4DAF95FFDD0690A8D669" alt="image"></p><p>上图显示了一批端点定义，这些端点并非我们自己在程序中创建，而是由spring-boot-starter-actuator模块根据应用依赖和配置自动创建出来的监控和管理端点。通过这些端点，我们可以实时的获取应用的各项监控指标，比如：访问<br>==/health==端点，我们可以获得如下返回的应用健康信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;status&quot;: &quot;UP&quot;,</span><br><span class="line">    &quot;diskSpace&quot;: &#123;</span><br><span class="line">        &quot;status&quot;: &quot;UP&quot;,</span><br><span class="line">        &quot;total&quot;: 491270434816,</span><br><span class="line">        &quot;free&quot;: 383870214144,</span><br><span class="line">        &quot;threshold&quot;: 10485760</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二-原生端点"><a href="#二-原生端点" class="headerlink" title="二,原生端点"></a><span id="2">二,原生端点</h2><p>通过在快速入门示例中添加==spring-boot-starter-actuator==模块，我们已经对它有了一个初步的认识。接下来，我们详细介绍一下==spring-boot-starter-actuator==模块中已经实现的一些原生端点。如果根据端点的作用来说，我们可以原生端点分为三大类：</p><ul><li>应用配置类：获取应用程序中加载的应用配置、环境变量、自动化配置报告等与Spring Boot应用密切相关的配置类信息。</li><li>度量指标类：获取应用程序运行过程中用于监控的度量指标，比如：内存信息、线程池信息、HTTP请求统计等。</li><li>操作控制类：提供了对应用的关闭等操作类功能。</li></ul><p>下面我们来详细了解一下这三类端点都分别可以为我们提供怎么样的有用信息和强大功能，以及我们如何去扩展和配置它们。</p><h3 id="2-1-应用配置类"><a href="#2-1-应用配置类" class="headerlink" title="2.1 应用配置类"></a><span id="2.1">2.1 应用配置类</h3><p>由于Spring Boot为了改善传统Spring应用繁杂的配置内容，采用了包扫描和自动化配置的机制来加载原本集中于xml文件中的各项内容。虽然这样的做法，让我们的代码变得非常简洁，但是整个应用的实例创建和依赖关系等信息都被离散到了各个配置类的注解上，这使得我们分析整个应用中资源和实例的各种关系变得非常的困难。而这类端点就可以帮助我们轻松的获取一系列关于Spring 应用配置内容的详细报告，比如：自动化配置的报告、Bean创建的报告、环境属性的报告等。</p><h4 id="autoconfig："><a href="#autoconfig：" class="headerlink" title="/autoconfig："></a><span id="2.1.1">/autoconfig：</h4><p>该端点用来获取应用的自动化配置报告，其中包括所有自动化配置的候选项。同时还列出了每个候选项自动化配置的各个先决条件是否满足。所以，该端点可以帮助我们方便的找到一些自动化配置为什么没有生效的具体原因。该报告内容将自动化配置内容分为两部分：</p><ul><li><strong>positiveMatches</strong>中返回的是条件匹配成功的自动化配置</li><li><strong>negativeMatches</strong>中返回的是条件匹配不成功的自动化配置</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;positiveMatches&quot;: &#123; // 条件匹配成功的</span><br><span class="line">        &quot;EndpointWebMvcAutoConfiguration&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;condition&quot;: &quot;OnClassCondition&quot;,</span><br><span class="line">                &quot;message&quot;: &quot;@ConditionalOnClass classes found: javax.servlet.Servlet,org.springframework.web.servlet.DispatcherServlet&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;condition&quot;: &quot;OnWebApplicationCondition&quot;,</span><br><span class="line">                &quot;message&quot;: &quot;found web application StandardServletEnvironment&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;negativeMatches&quot;: &#123;  // 条件不匹配成功的</span><br><span class="line">        &quot;HealthIndicatorAutoConfiguration.DataSourcesHealthIndicatorConfiguration&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;condition&quot;: &quot;OnClassCondition&quot;,</span><br><span class="line">                &quot;message&quot;: &quot;required @ConditionalOnClass classes not found: org.springframework.jdbc.core.JdbcTemplate&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从如上示例中我们可以看到，每个自动化配置候选项中都有一系列的条件，比如上面没有成功匹配的==HealthIndicatorAutoConfiguration.DataSourcesHealthIndicatorConfiguration==配置，它的先决条件就是需要在工程中包含==org.springframework.jdbc.core.JdbcTemplate==类，由于我们没有引入相关的依赖，它就不会执行自动化配置内容。所以，当我们发现有一些期望的配置没有生效时，就可以通过该端点来查看没有生效的具体原因。</p><h4 id="beans："><a href="#beans：" class="headerlink" title="/beans："></a><span id="2.1.2">/beans：</h4><p>该端点用来获取应用上下文中创建的所有Bean。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;context&quot;: &quot;hello:dev:8881&quot;,</span><br><span class="line">        &quot;parent&quot;: null,</span><br><span class="line">        &quot;beans&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;bean&quot;: &quot;org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration$DispatcherServletConfiguration&quot;,</span><br><span class="line">                &quot;scope&quot;: &quot;singleton&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration$DispatcherServletConfiguration$$EnhancerBySpringCGLIB$$3440282b&quot;,</span><br><span class="line">                &quot;resource&quot;: &quot;null&quot;,</span><br><span class="line">                &quot;dependencies&quot;: [</span><br><span class="line">                    &quot;serverProperties&quot;,</span><br><span class="line">                    &quot;spring.mvc.CONFIGURATION_PROPERTIES&quot;,</span><br><span class="line">                    &quot;multipartConfigElement&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;bean&quot;: &quot;dispatcherServlet&quot;,</span><br><span class="line">                &quot;scope&quot;: &quot;singleton&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;org.springframework.web.servlet.DispatcherServlet&quot;,</span><br><span class="line">                &quot;resource&quot;: &quot;class path resource [org/springframework/boot/autoconfigure/web/DispatcherServletAutoConfiguration$DispatcherServletConfiguration.class]&quot;,</span><br><span class="line">                &quot;dependencies&quot;: []</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>如上示例中，我们可以看到在每个bean中都包含了下面这几个信息：</p><ul><li><strong>bean</strong>：Bean的名称</li><li><strong>scope</strong>：Bean的作用域</li><li><strong>type</strong>：Bean的Java类型</li><li><strong>reource</strong>：class文件的具体路径</li><li><strong>dependencies</strong>：依赖的Bean名称</li></ul><h4 id="configprops："><a href="#configprops：" class="headerlink" title="/configprops："></a><span id="2.1.3">/configprops：</h4><p>该端点用来获取应用中配置的属性信息报告。从下面该端点返回示例的片段中，我们看到返回了关于该短信的配置信息，prefix属性代表了属性的配置前缀，properties代表了各个属性的名称和值。所以，我们可以通过该报告来看到各个属性的配置路径，比如我们要关闭该端点，就可以通过使用==endpoints.configprops.enabled=false==来完成设置。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;configurationPropertiesReportEndpoint&quot;: &#123;</span><br><span class="line">        &quot;prefix&quot;: &quot;endpoints.configprops&quot;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;id&quot;: &quot;configprops&quot;,</span><br><span class="line">            &quot;sensitive&quot;: true,</span><br><span class="line">            &quot;enabled&quot;: true</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="env："><a href="#env：" class="headerlink" title="/env："></a><span id="2.1.4">/env：</h4><p>该端点与<br>==/configprops==不同，它用来获取应用所有可用的环境属性报告。包括：环境变量、JVM属性、应用的配置配置、命令行中的参数。从下面该端点返回的示例片段中，我们可以看到它不仅返回了应用的配置属性，还返回了系统属性、环境变量等丰富的配置信息，其中也包括了应用还没有没有使用的配置。所以它可以帮助我们方便地看到当前应用可以加载的配置信息，并配合<br>==@ConfigurationProperties==注解将它们引入到我们的应用程序中来进行使用。另外，为了配置属性的安全，对于一些类似密码等敏感信息，该端点都会进行隐私保护，但是我们需要让属性名中包含：password、secret、key这些关键词，这样该端点在返回它们的时候会使用*来替代实际的属性值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;profiles&quot;: [</span><br><span class="line">        &quot;dev&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;server.ports&quot;: &#123;</span><br><span class="line">        &quot;local.server.port&quot;: 8881</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;servletContextInitParams&quot;: &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;systemProperties&quot;: &#123;</span><br><span class="line">        &quot;idea.version&quot;: &quot;2016.1.3&quot;,</span><br><span class="line">        &quot;java.runtime.name&quot;: &quot;Java(TM) SE Runtime Environment&quot;,</span><br><span class="line">        &quot;sun.boot.library.path&quot;: &quot;C:\\Program Files\\Java\\jdk1.8.0_91\\jre\\bin&quot;,</span><br><span class="line">        &quot;java.vm.version&quot;: &quot;25.91-b15&quot;,</span><br><span class="line">        &quot;java.vm.vendor&quot;: &quot;Oracle Corporation&quot;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;systemEnvironment&quot;: &#123;</span><br><span class="line">        &quot;configsetroot&quot;: &quot;C:\\WINDOWS\\ConfigSetRoot&quot;,</span><br><span class="line">        &quot;RABBITMQ_BASE&quot;: &quot;E:\\tools\\rabbitmq&quot;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;applicationConfig: [classpath:/application-dev.properties]&quot;: &#123;</span><br><span class="line">        &quot;server.port&quot;: &quot;8881&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;applicationConfig: [classpath:/application.properties]&quot;: &#123;</span><br><span class="line">        &quot;server.port&quot;: &quot;8885&quot;,</span><br><span class="line">        &quot;spring.profiles.active&quot;: &quot;dev&quot;,</span><br><span class="line">        &quot;info.app.name&quot;: &quot;spring-boot-hello&quot;,</span><br><span class="line">        &quot;info.app.version&quot;: &quot;v1.0.0&quot;,</span><br><span class="line">        &quot;spring.application.name&quot;: &quot;hello&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="mappings："><a href="#mappings：" class="headerlink" title="/mappings："></a><span id="2.1.5">/mappings：</h4><p>该端点用来返回所有Spring MVC的控制器映射关系报告。从下面的示例片段中，我们可以看该报告的信息与我们在启用Spring MVC的Web应用时输出的日志信息类似，其中bean属性标识了该映射关系的请求处理器，method属性标识了该映射关系的具体处理类和处理函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;/webjars/**&quot;: &#123;</span><br><span class="line">        &quot;bean&quot;: &quot;resourceHandlerMapping&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;/**&quot;: &#123;</span><br><span class="line">        &quot;bean&quot;: &quot;resourceHandlerMapping&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;/**/favicon.ico&quot;: &#123;</span><br><span class="line">        &quot;bean&quot;: &quot;faviconHandlerMapping&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;&#123;[/hello]&#125;&quot;: &#123;</span><br><span class="line">        &quot;bean&quot;: &quot;requestMappingHandlerMapping&quot;,</span><br><span class="line">        &quot;method&quot;: &quot;public java.lang.String com.didispace.web.HelloController.index()&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;&#123;[/mappings || /mappings.json],methods=[GET],produces=[application/json]&#125;&quot;: &#123;</span><br><span class="line">        &quot;bean&quot;: &quot;endpointHandlerMapping&quot;,</span><br><span class="line">        &quot;method&quot;: &quot;public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="info："><a href="#info：" class="headerlink" title="/info："></a><span id="2.1.6">/info：</h4><p>该端点用来返回一些应用自定义的信息。默认情况下，该端点只会返回一个空的json内容。我们可以在==application.properties==配置文件中通过info前缀来设置一些属性，比如下面这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">info.app.name=spring-boot-hello</span><br><span class="line">info.app.version=v1.0.0</span><br></pre></td></tr></table></figure><p>再访问/info端点，我们可以得到下面的返回报告，其中就包含了上面我们在应用自定义的两个参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;app&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;spring-boot-hello&quot;,</span><br><span class="line">        &quot;version&quot;: &quot;v1.0.0&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="2-2-度量指标类"><a href="#2-2-度量指标类" class="headerlink" title="2.2 度量指标类"></a><span id="2.2">2.2 度量指标类</h3><p>上面我们所介绍的应用配置类端点所提供的信息报告在应用启动的时候都已经基本确定了其返回内容，可以说是一个静态报告。而度量指标类端点提供的报告内容则是动态变化的，这些端点提供了应用程序在运行过程中的一些快照信息，比如：内存使用情况、HTTP请求统计、外部资源指标等。这些端点对于我们构建微服务架构中的监控系统非常有帮助，由于Spring Boot应用自身实现了这些端点，所以我们可以很方便地利用它们来收集我们想要的信息，以制定出各种自动化策略。下面，我们就来分别看看这些强大的端点功能。</p><h4 id="metrics："><a href="#metrics：" class="headerlink" title="/metrics："></a><span id="2.2.1">/metrics：</h4><p>该端点用来返回当前应用的各类重要度量指标，比如：内存信息、线程信息、垃圾回收信息等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mem&quot;: 541305,</span><br><span class="line">  &quot;mem.free&quot;: 317864,</span><br><span class="line">  &quot;processors&quot;: 8,</span><br><span class="line">  &quot;instance.uptime&quot;: 33376471,</span><br><span class="line">  &quot;uptime&quot;: 33385352,</span><br><span class="line">  &quot;systemload.average&quot;: -1,</span><br><span class="line">  &quot;heap.committed&quot;: 476672,</span><br><span class="line">  &quot;heap.init&quot;: 262144,</span><br><span class="line">  &quot;heap.used&quot;: 158807,</span><br><span class="line">  &quot;heap&quot;: 3701248,</span><br><span class="line">  &quot;nonheap.committed&quot;: 65856,</span><br><span class="line">  &quot;nonheap.init&quot;: 2496,</span><br><span class="line">  &quot;nonheap.used&quot;: 64633,</span><br><span class="line">  &quot;nonheap&quot;: 0,</span><br><span class="line">  &quot;threads.peak&quot;: 22,</span><br><span class="line">  &quot;threads.daemon&quot;: 20,</span><br><span class="line">  &quot;threads.totalStarted&quot;: 26,</span><br><span class="line">  &quot;threads&quot;: 22,</span><br><span class="line">  &quot;classes&quot;: 7669,</span><br><span class="line">  &quot;classes.loaded&quot;: 7669,</span><br><span class="line">  &quot;classes.unloaded&quot;: 0,</span><br><span class="line">  &quot;gc.ps_scavenge.count&quot;: 7,</span><br><span class="line">  &quot;gc.ps_scavenge.time&quot;: 118,</span><br><span class="line">  &quot;gc.ps_marksweep.count&quot;: 2,</span><br><span class="line">  &quot;gc.ps_marksweep.time&quot;: 234,</span><br><span class="line">  &quot;httpsessions.max&quot;: -1,</span><br><span class="line">  &quot;httpsessions.active&quot;: 0,</span><br><span class="line">  &quot;gauge.response.beans&quot;: 55,</span><br><span class="line">  &quot;gauge.response.env&quot;: 10,</span><br><span class="line">  &quot;gauge.response.hello&quot;: 5,</span><br><span class="line">  &quot;gauge.response.metrics&quot;: 4,</span><br><span class="line">  &quot;gauge.response.configprops&quot;: 153,</span><br><span class="line">  &quot;gauge.response.star-star&quot;: 5,</span><br><span class="line">  &quot;counter.status.200.beans&quot;: 1,</span><br><span class="line">  &quot;counter.status.200.metrics&quot;: 3,</span><br><span class="line">  &quot;counter.status.200.configprops&quot;: 1,</span><br><span class="line">  &quot;counter.status.404.star-star&quot;: 2,</span><br><span class="line">  &quot;counter.status.200.hello&quot;: 11,</span><br><span class="line">  &quot;counter.status.200.env&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的示例中，我们看到有这些重要的度量值：</p><ul><li><strong>系统信息</strong>：包括处理器数量processors、运行时间uptime和instance.uptime、系统平均负载systemload.average。</li><li><strong>mem.*</strong>：内存概要信息，包括分配给应用的总内存数量以及当前空闲的内存数量。这些信息来自java.lang.Runtime。</li><li><strong>heap.*</strong>：堆内存使用情况。这些信息来自java.lang.management.MemoryMXBean接口中getHeapMemoryUsage方法获取的java.lang.management.MemoryUsage。</li><li><strong>nonheap.*</strong>：非堆内存使用情况。这些信息来自java.lang.management.MemoryMXBean接口中getNonHeapMemoryUsage方法获取的java.lang.management.MemoryUsage。</li><li><strong>threads.*</strong>：线程使用情况，包括线程数、守护线程数（daemon）、线程峰值（peak）等，这些数据均来自java.lang.management.ThreadMXBean。</li><li><strong>classes.*</strong>：应用加载和卸载的类统计。这些数据均来自java.lang.management.ClassLoadingMXBean。</li><li><strong>gc.*</strong>：垃圾收集器的详细信息，包括垃圾回收次数gc.ps_scavenge.count、垃圾回收消耗时间gc.ps_scavenge.time、标记-清除算法的次数gc.ps_marksweep.count、标记-清除算法的消耗时间gc.ps_marksweep.time。这些数据均来自java.lang.management.GarbageCollectorMXBean。</li><li><strong>httpsessions.*</strong>：Tomcat容器的会话使用情况。包括最大会话数httpsessions.max和活跃会话数httpsessions.active。该度量指标信息仅在引入了嵌入式Tomcat作为应用容器的时候才会提供。</li><li><strong>gauge.*</strong>：HTTP请求的性能指标之一，它主要用来反映一个绝对数值。比如上面示例中的gauge.response.hello: 5，它表示上一次hello请求的延迟时间为5毫秒。</li><li><strong>counter.*</strong>：HTTP请求的性能指标之一，它主要作为计数器来使用，记录了增加量和减少量。如上示例中counter.status.200.hello: 11，它代表了hello请求返回200状态的次数为11。</li></ul><p>对于<strong>gauge.*</strong>和<strong>counter.*</strong>的统计，这里有一个特殊的内容请求star-star，它代表了对静态资源的访问。这两类度量指标非常有用，我们不仅可以使用它默认的统计指标，还可以在程序中轻松的增加自定义统计值。只需要通过注入==org.springframework.boot.actuate.metrics.CounterService和org.springframework.boot.actuate.metrics.GaugeService==来实现自定义的统计指标信息。比如：我们可以像下面这样自定义实现对hello接口的访问次数统计。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    </span><br><span class="line">    @Autowired</span><br><span class="line">    private CounterService counterService;</span><br><span class="line"></span><br><span class="line">    @RequestMapping(&quot;/hello&quot;)</span><br><span class="line">    public String greet() &#123;</span><br><span class="line">        counterService.increment(&quot;didispace.hello.count&quot;);</span><br><span class="line">        return &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>/metrics端点可以提供应用运行状态的完整度量指标报告，这项功能非常的实用，但是对于监控系统中的各项监控功能，它们的监控内容、数据收集频率都有所不同，如果我们每次都通过全量获取报告的方式来收集，略显粗暴。所以，我们还可以通过/metrics/{name}接口来更细粒度的获取度量信息，比如我们可以通过访问/metrics/mem.free来获取当前可用内存数量。</p><h4 id="health："><a href="#health：" class="headerlink" title="/health："></a><span id="2.2.2">/health：</h4><p>该端点在一开始的示例中我们已经使用过了，它用来获取应用的各类健康指标信息。在spring-boot-starter-actuator模块中自带实现了一些常用资源的健康指标检测器。这些检测器都通过HealthIndicator接口实现，并且会根据依赖关系的引入实现自动化装配，比如用于检测磁盘的DiskSpaceHealthIndicator、检测DataSource连接是否可用的DataSourceHealthIndicator等。有时候，我们可能还会用到一些Spring Boot的Starter POMs中还没有封装的产品来进行开发，比如：当使用RocketMQ作为消息代理时，由于没有自动化配置的检测器，所以我们需要自己来实现一个用来采集健康信息的检测器。比如，我们可以在Spring Boot的应用中，为org.springframework.boot.actuate.health.HealthIndicator接口实现一个对RocketMQ的检测器类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class RocketMQHealthIndicator implements HealthIndicator &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Health health() &#123;</span><br><span class="line">        int errorCode = check();</span><br><span class="line">        if (errorCode != 0) &#123;</span><br><span class="line">          return Health.down().withDetail(&quot;Error Code&quot;, errorCode).build();</span><br><span class="line">        &#125;</span><br><span class="line">        return Health.up().build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  private int check() &#123;</span><br><span class="line">     // 对监控对象的检测操作</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过重写health()函数来实现健康检查，返回的Heath对象中，共有两项内容，一个是状态信息，除了该示例中的UP与DOWN之外，还有UNKNOWN和OUT_OF_SERVICE，可以根据需要来实现返回；还有一个详细信息，采用Map的方式存储，在这里通过withDetail函数，注入了一个Error Code信息，我们也可以填入一下其他信息，比如，检测对象的IP地址、端口等。重新启动应用，并访问/health接口，我们在返回的JSON字符串中，将会包含了如下信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;rocketMQ&quot;: &#123;</span><br><span class="line">  &quot;status&quot;: &quot;UP&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="dump："><a href="#dump：" class="headerlink" title="/dump："></a><span id="2.2.3">/dump：</h4><p>该端点用来暴露程序运行中的线程信息。它使用java.lang.management.ThreadMXBean的dumpAllThreads方法来返回所有含有同步信息的活动线程详情。</p><h4 id="trace："><a href="#trace：" class="headerlink" title="/trace："></a><span id="2.2.4">/trace：</h4><p>该端点用来返回基本的HTTP跟踪信息。默认情况下，跟踪信息的存储采用org.springframework.boot.actuate.trace.InMemoryTraceRepository实现的内存方式，始终保留最近的100条请求记录。它记录的内容格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;timestamp&quot;: 1482570022463,</span><br><span class="line">        &quot;info&quot;: &#123;</span><br><span class="line">            &quot;method&quot;: &quot;GET&quot;,</span><br><span class="line">            &quot;path&quot;: &quot;/metrics/mem&quot;,</span><br><span class="line">            &quot;headers&quot;: &#123;</span><br><span class="line">                &quot;request&quot;: &#123;</span><br><span class="line">                    &quot;host&quot;: &quot;localhost:8881&quot;,</span><br><span class="line">                    &quot;connection&quot;: &quot;keep-alive&quot;,</span><br><span class="line">                    &quot;cache-control&quot;: &quot;no-cache&quot;,</span><br><span class="line">                    &quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36&quot;,</span><br><span class="line">                    &quot;postman-token&quot;: &quot;9817ea4d-ad9d-b2fc-7685-9dff1a1bc193&quot;,</span><br><span class="line">                    &quot;accept&quot;: &quot;*/*&quot;,</span><br><span class="line">                    &quot;accept-encoding&quot;: &quot;gzip, deflate, sdch&quot;,</span><br><span class="line">                    &quot;accept-language&quot;: &quot;zh-CN,zh;q=0.8&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;response&quot;: &#123;</span><br><span class="line">                    &quot;X-Application-Context&quot;: &quot;hello:dev:8881&quot;,</span><br><span class="line">                    &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot;,</span><br><span class="line">                    &quot;Transfer-Encoding&quot;: &quot;chunked&quot;,</span><br><span class="line">                    &quot;Date&quot;: &quot;Sat, 24 Dec 2016 09:00:22 GMT&quot;,</span><br><span class="line">                    &quot;status&quot;: &quot;200&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h3 id="2-3-操作控制类"><a href="#2-3-操作控制类" class="headerlink" title="2.3 操作控制类"></a><span id="2.3">2.3 操作控制类</h3><p>仔细的读者可能会发现，我们在“初识Actuator”时运行示例的控制台中输出的所有监控端点，已经在介绍应用配置类端点和度量指标类端点时都讲解完了。那么还有哪些是操作控制类端点呢？实际上，由于之前介绍的所有端点都是用来反映应用自身的属性或是运行中的状态，相对于操作控制类端点没有那么敏感，所以他们默认都是启用的。而操作控制类端点拥有更强大的控制能力，如果要使用它们的话，需要通过属性来配置开启。</p><p>在原生端点中，只提供了一个用来关闭应用的端点：/shutdown。我们可以通过如下配置开启它：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">endpoints.shutdown.enabled=true</span><br></pre></td></tr></table></figure><p>在配置了上述属性之后，只需要访问该应用的/shutdown端点就能实现关闭该应用的远程操作。由于开放关闭应用的操作本身是一件非常危险的事，所以真正在线上使用的时候，我们需要对其加入一定的保护机制，比如：定制Actuator的端点路径、整合Spring Security进行安全校验等。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Spring-Boot-Actuator监控端点&quot;&gt;&lt;a href=&quot;#Spring-Boot-Actuator监控端点&quot; class=&quot;headerlink&quot; title=&quot;Spring Boot Actuator监控端点&quot;&gt;&lt;/a&gt;Spring Boot Ac
      
    
    </summary>
    
    
      <category term="微服务" scheme="https://hicker000.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="SpringBoot" scheme="https://hicker000.github.io/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://hicker000.github.io/2019/11/10/hello-world/"/>
    <id>https://hicker000.github.io/2019/11/10/hello-world/</id>
    <published>2019-11-10T05:30:39.000Z</published>
    <updated>2019-11-10T08:13:48.919Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="发大水发达"><a href="#发大水发达" class="headerlink" title="发大水发达"></a>发大水发达</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
      <category term="测试" scheme="https://hicker000.github.io/categories/%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="测试-1" scheme="https://hicker000.github.io/tags/%E6%B5%8B%E8%AF%95-1/"/>
    
  </entry>
  
</feed>
